{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic feature examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ScriptFeaturizer import scripts_to_tfidf, num_lines\n",
    "from FeatureUtils import load_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bp2221/py/test/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['cut', 'fade', 'll', 'scene', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1147, 3849)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scripts, titles = load_scripts(r'data/scraping/texts/')\n",
    "X, vocab = scripts_to_tfidf(raw_scripts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nTen Things I Hate About You - by Karen McCullah Lutz & Kirsten Smith\\n\\n                               TEN THINGS I HATE ABOUT YOU\\n          \\n                written by Karen McCullah Lutz & Kirsten Smith\\n          \\n              based on \\'Taming of the Shrew\" by William Shakespeare\\n          \\n          Revision November 12, 1997\\n          \\n          \\n          PADUA HIGH SCHOOL - DAY\\n          \\n          Welcome to Padua High School,, your typical urban-suburban \\n          high school in Portland, Oregon.  Smarties, Skids, Preppies, \\n          Granolas. Loners, Lovers, the In and the Out Crowd rub sleep \\n          out of their eyes and head for the main building.\\n          \\n          PADUA HIGH PARKING LOT - DAY\\n          \\n          KAT STRATFORD, eighteen, pretty -- but trying hard not to be \\n          -- in a baggy granny dress and glasses, balances a cup of \\n          coffee and a backpack as she climbs out of her battered, \\n          baby blue \\'75 Dodge Dart.\\n          \\n        '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scripts[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find names in the script\n",
    "\n",
    "\n",
    "num_lines(raw_scripts[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spacy feature utils examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ScriptFeaturizer import scripts_to_tfidf, df_to_stats\n",
    "from FeatureUtils import load_scripts, make_doc_df, series_to_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "raw_scripts, titles = load_scripts(r'data/scraping/texts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.015120\n"
     ]
    }
   ],
   "source": [
    "nw = datetime.now()\n",
    "df = make_doc_df(raw_scripts[0])\n",
    "print(datetime.now() - nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>ner_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ten</td>\n",
       "      <td>ten</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nummod</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>things</td>\n",
       "      <td>thing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>relcl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19169</th>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19170</th>\n",
       "      <td>comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19171</th>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19172</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19173</th>\n",
       "      <td>imsdb</td>\n",
       "      <td>imsdb</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19174 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text    lemma    pos  tag       dep shape  is_alpha  is_stop  \\\n",
       "0                         SPACE  _SP                     False    False   \n",
       "1           ten      ten    NUM   CD    nummod   xxx      True     True   \n",
       "2        things    thing   NOUN  NNS      ROOT  xxxx      True    False   \n",
       "3             i        i   PRON  PRP     nsubj     x      True     True   \n",
       "4          hate     hate   VERB  VBP     relcl  xxxx      True    False   \n",
       "...         ...      ...    ...  ...       ...   ...       ...      ...   \n",
       "19169      user     user   NOUN   NN  compound  xxxx      True    False   \n",
       "19170  comments  comment   NOUN  NNS      dobj  xxxx      True    False   \n",
       "19171      back     back    ADV   RB    advmod  xxxx      True     True   \n",
       "19172        to       to    ADP   IN      prep    xx      True     True   \n",
       "19173     imsdb    imsdb  PROPN  NNP      pobj  xxxx      True    False   \n",
       "\n",
       "      ner_obj  \n",
       "0        None  \n",
       "1        TIME  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "...       ...  \n",
       "19169    None  \n",
       "19170    None  \n",
       "19171    None  \n",
       "19172    None  \n",
       "19173    None  \n",
       "\n",
       "[19174 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 169,  692,  688,   37,    8,    5,   20,    9,  242, 2757,   35,\n",
       "           8,  239,    1]),\n",
       " array(['CARDINAL', 'DATE', 'FAC', 'GPE', 'LANGUAGE', 'LOC', 'NORP',\n",
       "        'ORDINAL', 'ORG', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME',\n",
       "        'WORK_OF_ART'], dtype=object))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_stats(df, 'ner_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ten thing i hate about -PRON- by karen mccullah lutz kirsten smith ten thing i hate about -PRON- w\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bp2221/py/test/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['cut', 'fade', 'll', 'scene', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10', '11', '12', '141', '16th', '1995', '1997', '400', '75', '90210']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lemmatized_text = series_to_doc(df.lemma)\n",
    "print(lemmatized_text[:100])\n",
    "test = scripts_to_tfidf([lemmatized_text])\n",
    "test[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word embeddings example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from ScriptFeaturizer import scripts_to_tfidf, scripts_to_embeddings\n",
    "from FeatureUtils import tokenize_script, load_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "raw_scripts, titles = load_scripts(r'data/scraping/texts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [tokenize_script(script, stop_words=True) for script in raw_scripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:31.135198\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "nw = datetime.now()\n",
    "model = Word2Vec(docs, \n",
    "                 min_count=100, \n",
    "                 size=100, \n",
    "                 window=5, \n",
    "                 max_vocab_size=2000\n",
    "                )\n",
    "print(datetime.now() - nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'models/word2vec.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what's done\n",
    "- length of script `num_lines`\n",
    "- `FeatureUtils` for feature engineering helper functions\n",
    "  - master spacy df `make_doc_df`\n",
    "  - `series_to_doc` for lemmatizing and other word transformations\n",
    "- `ScriptFeaturizer` updates for include spacy summary features via pandas methods\n",
    "  - stats feature vectors `df_to_stats`\n",
    "- word2vec skeleton framework & small model (won't scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "- thematic counts?\n",
    "  - swear words\n",
    "  - sex words\n",
    "- word2vec second model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
